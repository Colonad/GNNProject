# ==============================================================================
# Model: GIN (Graph Isomorphism Network) — Training CLI Schema
# ==============================================================================
# This file follows the **ModelCfg** schema defined in src/cli/train.py
# (NOT the raw GINConfig class). The CLI converts these fields into argparse
# flags for src/train/loop.py. You can override anything from the command line.
#
# Typical usages:
#   # Plain GIN on ESOL (defaults here):
#   python -m src.cli.train +model=@configs/model/gin.yaml data.name=ESOL eval=scaffold seed=0
#
#   # Switch pooling and make it deeper:
#   python -m src.cli.train +model=@configs/model/gin.yaml model.pool=sum model.num_layers=7
#
#   # Turn on virtual node and wider readout:
#   python -m src.cli.train +model=@configs/model/gin.yaml model.virtual_node=true model.readout_hidden_mult=2.0
#
# Notes:
# - If you pass just `model=gin` on CLI, the shorthand is coerced to ModelCfg with name=gin.
#   Using this YAML gives you a centralized, reviewable set of GIN defaults.
# - GINE path is enabled by setting `model.use_edge_attr=true` **and**
#   ensuring the datamodule provides `edge_attr` (e.g., MPNN/QM9 with bond features).
# ==============================================================================

model:
  # ----------------------------------------------------------
  # Identity
  # ----------------------------------------------------------
  name: gin                  # gin | mpnn  (GIN here)

  # ----------------------------------------------------------
  # Core architecture (shared schema from ModelCfg)
  # ----------------------------------------------------------
  hidden_dim: 128            # Node embedding width
  num_layers: 5              # Message-passing depth
  pool: mean                 # sum | mean | max     (graph readout)
  act: relu                  # relu | gelu | leaky_relu | elu
  dropout: 0.10              # Dropout after each block and in readout MLP
  init: kaiming              # kaiming | xavier | none

  # ----------------------------------------------------------
  # Normalization / residuals (note these are "flip" flags)
  #   - BatchNorm ON  by default  → no_batch_norm=false
  #   - Residuals ON by default   → no_residual=false
  # ----------------------------------------------------------
  no_batch_norm: false       # true → adds --no-batch-norm
  no_residual: false         # true → adds --no-residual

  # ----------------------------------------------------------
  # GIN / GINE specific toggles
  # ----------------------------------------------------------
  use_edge_attr: false       # true → requests GINE path if edge_attr exists
  no_learn_eps: false        # true → disables learnable ε in GIN aggregation
  virtual_node: false        # true → GIN-VN (global token)
  readout_layers: 2          # ≥1; number of linear layers in graph readout MLP
  readout_hidden_mult: 1.0   # scale of hidden width in readout MLP (× hidden_dim)

  # ----------------------------------------------------------
  # MPNN-only knobs (harmless here; ignored by GIN)
  # ----------------------------------------------------------
  aggr: add                  # add | mean | max (used by MPNN)
  no_gru: false              # true → disable GRU in MPNN

# ------------------------------------------------------------------------------
# Preset bundles (optional): quickly switch model flavors by overriding a block.
# Use with: +model=@configs/model/gin.yaml +preset=fast_debug
# Then pick one of below via: +model_preset=<key>
# ------------------------------------------------------------------------------
# These are purely informational helpers; Hydra doesn’t activate them automatically.
# To use, override fields directly from CLI or create separate files per preset.
presets:
  fast_debug:
    hidden_dim: 64
    num_layers: 3
    dropout: 0.0
    no_batch_norm: true
    no_residual: true
  strong_gin:
    hidden_dim: 256
    num_layers: 7
    dropout: 0.1
    no_batch_norm: false
    no_residual: false
  gine_with_vn:
    use_edge_attr: true
    virtual_node: true
    hidden_dim: 160
    num_layers: 6
    readout_layers: 3
    readout_hidden_mult: 1.5

# ------------------------------------------------------------------------------
# Documentation / provenance (kept for manifests & reports)
# ------------------------------------------------------------------------------
meta:
  description: "GIN (with optional GINE, VN) defaults for molecular property prediction."
  version: "1.0"
  source: "configs/model/gin.yaml"
  notes:
    - "Set model.use_edge_attr=true only when your datamodule provides edge_attr."
    - "Learnable epsilon is ON by default (no_learn_eps=false)."
    - "Virtual node improves long-range info flow on some datasets; try enabling it."
